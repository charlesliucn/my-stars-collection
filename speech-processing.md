# Speech Processing Repos

- wer_are_we [(https://github.com/syhw/wer_are_we)](https://github.com/syhw/wer_are_we)
- awesome-speech [(https://github.com/mxer/awesome-speech)](https://github.com/mxer/awesome-speech)
- awesome-speech-recognition-speech-synthesis-papers [(https://github.com/zzw922cn/awesome-speech-recognition-speech-synthesis-papers)](https://github.com/zzw922cn/awesome-speech-recognition-speech-synthesis-papers)
- asr-study [(https://github.com/igormq/asr-study)](https://github.com/igormq/asr-study)
- ASR_Theory [(https://github.com/zw76859420/ASR_Theory)](https://github.com/zw76859420/ASR_Theory)

## Audio Analysis
- Pydub [(https://github.com/jiaaro/pydub)](https://github.com/jiaaro/pydub)
- pyAudioAnalysis [(https://github.com/tyiannak/pyAudioAnalysis)](https://github.com/tyiannak/pyAudioAnalysis)
- python_speech_features [(https://github.com/jameslyons/python_speech_features)](https://github.com/jameslyons/python_speech_features)
- Pytorch Audio [(https://github.com/pytorch/audio)](https://github.com/pytorch/audio)
- SincNet [(https://github.com/mravanelli/SincNet)](https://github.com/mravanelli/SincNet)
- mir_eval [(https://github.com/craffel/mir_eval)](https://github.com/craffel/mir_eval)
- muda [(https://github.com/bmcfee/muda)](https://github.com/bmcfee/muda)
- praatIO [(https://github.com/timmahrt/praatIO)](https://github.com/timmahrt/praatIO)

## Speech Recognition

### Toolkits
- awesome-kaldi [(https://github.com/YoavRamon/awesome-kaldi)](https://github.com/YoavRamon/awesome-kaldi)
- kaldi [(https://github.com/tramphero/kaldi)](https://github.com/tramphero/kaldi)
- pykaldi [(https://github.com/pykaldi/pykaldi)](https://github.com/pykaldi/pykaldi)
- pykaldi2 [(https://github.com/jzlianglu/pykaldi2)](https://github.com/jzlianglu/pykaldi2)
- py-kaldi-asr [(https://github.com/gooofy/py-kaldi-asr)](https://github.com/gooofy/py-kaldi-asr)
- pytorch-kaldi [(https://github.com/mravanelli/pytorch-kaldi)](https://github.com/mravanelli/pytorch-kaldi)
- tfkaldi [(https://github.com/vrenkens/tfkaldi)](https://github.com/vrenkens/tfkaldi)
- keras-kaldi [(https://github.com/dspavankumar/keras-kaldi)](https://github.com/dspavankumar/keras-kaldi)
- kaldi-ctc [(https://github.com/lingochamp/kaldi-ctc)](https://github.com/lingochamp/kaldi-ctc)
- kaldi-onnx [(https://github.com/XiaoMi/kaldi-onnx)](https://github.com/XiaoMi/kaldi-onnx)
- kaldi2htk [(https://github.com/dansoutner/kaldi2htk)](https://github.com/dansoutner/kaldi2htk)
- multi-task-kaldi [(https://github.com/JRMeyer/multi-task-kaldi)](https://github.com/JRMeyer/multi-task-kaldi)
- kaldi-gstreamer-server [(https://github.com/alumae/kaldi-gstreamer-server)](https://github.com/alumae/kaldi-gstreamer-server)
- kaldi-android-demo [https://github.com/alphacep/kaldi-android-demo](https://github.com/alphacep/kaldi-android-demo)
- kaldi-io-for-python [(https://github.com/vesis84/kaldi-io-for-python)](https://github.com/vesis84/kaldi-io-for-python)
- kaldiio [(https://github.com/nttcslab-sp/kaldiio)](https://github.com/nttcslab-sp/kaldiio)
- kaldi-websocket-python [(https://github.com/alphacep/kaldi-websocket-python)](https://github.com/alphacep/kaldi-websocket-python)
- wake-word detection [https://github.com/kaldi-asr/kaldi/pull/3467](https://github.com/kaldi-asr/kaldi/pull/3467)
- CSLT-THU kaldi cases [(https://github.com/tzyll/kaldi)](https://github.com/tzyll/kaldi)
---
- DeepSpeech [(https://github.com/mozilla/DeepSpeech)](https://github.com/mozilla/DeepSpeech)
- deepspeech.pytorch [(https://github.com/SeanNaren/deepspeech.pytorch)](https://github.com/SeanNaren/deepspeech.pytorch)
- Synthetic-Boosted-DeepSpeech [(https://github.com/rolczynski/Synthetic-Boosted-DeepSpeech)](https://github.com/rolczynski/Synthetic-Boosted-DeepSpeech)
- espnet [(https://github.com/espnet/espnet)](https://github.com/espnet/espnet)
- espnet-tts [(https://github.com/r9y9/icassp2020-espnet-tts-merlin-baseline)](https://github.com/r9y9/icassp2020-espnet-tts-merlin-baseline)
- espnet-semi-supervised [(https://github.com/ShigekiKarita/espnet-semi-supervised)](https://github.com/ShigekiKarita/espnet-semi-supervised)
- espnet-tutorial [(https://github.com/espnet/interspeech2019-tutorial)](https://github.com/espnet/interspeech2019-tutorial)
- espresso [(https://github.com/freewym/espresso)](https://github.com/freewym/espresso)
- HTK [(https://github.com/open-speech/HTK)](https://github.com/open-speech/HTK)
- julius [(https://github.com/julius-speech/julius)](https://github.com/julius-speech/julius)
- wav2letter [(https://github.com/facebookresearch/wav2letter)](https://github.com/facebookresearch/wav2letter)
- eesen [(https://github.com/srvk/eesen)](https://github.com/srvk/eesen)
- delta [(https://github.com/didi/delta)](https://github.com/didi/delta)
---
- Lyric_ASR [(https://github.com/jackyyy0228/Lyric_ASR)](https://github.com/jackyyy0228/Lyric_ASR)
- Speech-Transformer [(https://github.com/kaituoxu/Speech-Transformer)](https://github.com/kaituoxu/Speech-Transformer)
- Speech-Tranformer-Pytorch [(https://github.com/ZhengkunTian/Speech-Tranformer-Pytorch)](https://github.com/ZhengkunTian/Speech-Tranformer-Pytorch)
- Alibaba-MIT-Speech [(https://github.com/alibaba/Alibaba-MIT-Speech)](https://github.com/alibaba/Alibaba-MIT-Speech)
- tacotron_asr [(https://github.com/Kyubyong/tacotron_asr)](https://github.com/Kyubyong/tacotron_asr)
- asr_preprocessing [(https://github.com/hirofumi0810/asr_preprocessing)](https://github.com/hirofumi0810/asr_preprocessing)
- ASRT_SpeechRecognition [(https://github.com/nl8590687/ASRT_SpeechRecognition)](https://github.com/nl8590687/ASRT_SpeechRecognition)
- Automatic_Speech_Recognition [(https://github.com/zzw922cn/Automatic_Speech_Recognition)](https://github.com/zzw922cn/Automatic_Speech_Recognition)
- speech_recognition [(https://github.com/Uberi/speech_recognition)](https://github.com/Uberi/speech_recognition)
- speech-language-processing [(https://github.com/edobashira/speech-language-processing)](https://github.com/edobashira/speech-language-processing)
- attention-lvcsr [(https://github.com/rizar/attention-lvcsr)](https://github.com/rizar/attention-lvcsr)
- end2end-asr-pytorch [(https://github.com/gentaiscool/end2end-asr-pytorch)](https://github.com/gentaiscool/end2end-asr-pytorch)
- E2E-ASR [(https://github.com/HawkAaron/E2E-ASR)](https://github.com/HawkAaron/E2E-ASR)
- tensorflow_end2end_speech_recognition [(https://github.com/hirofumi0810/tensorflow_end2end_speech_recognition)](https://github.com/hirofumi0810/tensorflow_end2end_speech_recognition)
- ASR_Syllable [(https://github.com/zw76859420/ASR_Syllable)](https://github.com/zw76859420/ASR_Syllable)
- speech-to-text [(https://github.com/yh1008/speech-to-text)](https://github.com/yh1008/speech-to-text)
- speech [(https://github.com/awni/speech)](https://github.com/awni/speech)
- live-transcribe-speech-engine [(https://github.com/google/live-transcribe-speech-engine)](https://github.com/google/live-transcribe-speech-engine)
- Mandarin ASR [(https://github.com/libai3/masr)](https://github.com/libai3/masr)
- zamia-speech [(https://github.com/gooofy/zamia-speech)](https://github.com/gooofy/zamia-speech)
- neural_sp [(https://github.com/hirofumi0810/neural_sp)](https://github.com/hirofumi0810/neural_sp)
- pytorch-asr [(https://github.com/jinserk/pytorch-asr)](https://github.com/jinserk/pytorch-asr)
- ctc-asr [(https://github.com/mdangschat/ctc-asr)](https://github.com/mdangschat/ctc-asr)
- kaggle_speech_recognition [(https://github.com/huschen/kaggle_speech_recognition)](https://github.com/huschen/kaggle_speech_recognition)
- Sigmedia-AVSR [(https://github.com/georgesterpu/Sigmedia-AVSR)](https://github.com/georgesterpu/Sigmedia-AVSR)
- MAX-Speech-to-Text-Converter [(https://github.com/IBM/MAX-Speech-to-Text-Converter)](https://github.com/IBM/MAX-Speech-to-Text-Converter)
- asr-evaluation [(https://github.com/belambert/asr-evaluation)](https://github.com/belambert/asr-evaluation)
- pansori [(https://github.com/yc9701/pansori)](https://github.com/yc9701/pansori)

### Pronunciation Lexicon
- DaCiDian [(https://github.com/aishell-foundation/DaCiDian)](https://github.com/aishell-foundation/DaCiDian)
- THUOCL [(https://github.com/thunlp/THUOCL)](https://github.com/thunlp/THUOCL)
- cmu-pronouncing-dictionary [(https://github.com/words/cmu-pronouncing-dictionary)](https://github.com/words/cmu-pronouncing-dictionary)

### G2P
- g2p [(https://github.com/Kyubyong/g2p)](https://github.com/Kyubyong/g2p)
- g2p-seq2seq [(https://github.com/cmusphinx/g2p-seq2seq)](https://github.com/cmusphinx/g2p-seq2seq)
- Phonetisaurus [(https://github.com/AdolfVonKleist/Phonetisaurus)](https://github.com/AdolfVonKleist/Phonetisaurus)
- g2pC [(https://github.com/Kyubyong/g2pC)](https://github.com/Kyubyong/g2pC)
- sequitur-g2p [(https://github.com/sequitur-g2p/sequitur-g2p)](https://github.com/sequitur-g2p/sequitur-g2p)

### Acoustic Modeling (specifically)
- NN acoustic modeling (chainer) [(https://github.com/OrcusCZ/NNAcousticModeling)](https://github.com/OrcusCZ/NNAcousticModeling)

### Language Modeling
- pocolm [(https://github.com/danpovey/pocolm)](https://github.com/danpovey/pocolm)
- kenlm [(https://github.com/kpu/kenlm)](https://github.com/kpu/kenlm)
- irstlm [(https://github.com/irstlm-team/irstlm)](https://github.com/irstlm-team/irstlm)
- faster-rnnlm [(https://github.com/yandex/faster-rnnlm)](https://github.com/yandex/faster-rnnlm)

### Decoders
- kaldi-decoders [(https://github.com/jpuigcerver/kaldi-decoders)](https://github.com/jpuigcerver/kaldi-decoders)
- kaldi-decoders [(https://github.com/chenzhehuai/kaldi-decoders)](https://github.com/chenzhehuai/kaldi-decoders)
- rnnlm2wfst [(https://github.com/glecorve/rnnlm2wfst)](https://github.com/glecorve/rnnlm2wfst)
- kaldi Lookahead Decoding [https://github.com/kaldi-asr/kaldi/pull/3616](https://github.com/kaldi-asr/kaldi/pull/3616)
- Incremental Lattice Determinization [https://github.com/kaldi-asr/kaldi/pull/3317](https://github.com/kaldi-asr/kaldi/pull/3317)

### Audio Alignment
- kaldi-long-audio-alignment [(https://github.com/srinivr/kaldi-long-audio-alignment)](https://github.com/srinivr/kaldi-long-audio-alignment)
- speech-aligner [(https://github.com/open-speech/speech-aligner)](https://github.com/open-speech/speech-aligner)
- sail_align [(https://github.com/nassosoassos/sail_align)](https://github.com/nassosoassos/sail_align)
- forced-alignment-tools [(https://github.com/pettarin/forced-alignment-tools)](https://github.com/pettarin/forced-alignment-tools)
- Montreal-Forced-Aligner [(https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner)](https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner)
- jamendolyrics [(https://github.com/f90/jamendolyrics)](https://github.com/f90/jamendolyrics)
- Lyrics-to-Audio-Alignment [(https://github.com/ronggong/MIREX-2018-Automatic-Lyrics-to-Audio-Alignment)](https://github.com/ronggong/MIREX-2018-Automatic-Lyrics-to-Audio-Alignment)
- Lyrics-to-Audio-Alignment [(https://github.com/rupakvignesh/Lyrics-to-Audio-Alignment)](https://github.com/rupakvignesh/Lyrics-to-Audio-Alignment)

### GOP(Goodness of Pronunciation)
- kaldi-dnn-ali-gop [(https://github.com/tbright17/kaldi-dnn-ali-gop)](https://github.com/tbright17/kaldi-dnn-ali-gop)
- kaldi-gop [(https://github.com/jimbozhang/kaldi-gop)](https://github.com/jimbozhang/kaldi-gop)

## Speech Synthesis
- tacotron [(https://github.com/keithito/tacotron)](https://github.com/keithito/tacotron)
- tacotron [(https://github.com/Kyubyong/tacotron)](https://github.com/Kyubyong/tacotron)
- tacotron [(https://github.com/begeekmyfriend/tacotron)](https://github.com/begeekmyfriend/tacotron)
- tacotron2 [(https://github.com/NVIDIA/tacotron2)](https://github.com/NVIDIA/tacotron2)
- Tacotron-2 [(https://github.com/Rayhane-mamah/Tacotron-2)](https://github.com/Rayhane-mamah/Tacotron-2)
- Tacotron-2-Chinese [(https://github.com/JasonWei512/Tacotron-2-Chinese)](https://github.com/JasonWei512/Tacotron-2-Chinese)
- WaveRNN [(https://github.com/fatchord/WaveRNN)](https://github.com/fatchord/WaveRNN)
- merlin [(https://github.com/CSTR-Edinburgh/merlin)](https://github.com/CSTR-Edinburgh/merlin)
- melgan [(https://github.com/seungwonpark/melgan)](https://github.com/seungwonpark/melgan)
- stt-benchmark [(https://github.com/Picovoice/stt-benchmark)](https://github.com/Picovoice/stt-benchmark)
- Voice Conversion [(https://github.com/kan-bayashi/INTERSPEECH19_TUTORIAL)](https://github.com/kan-bayashi/INTERSPEECH19_TUTORIAL)
- Voice Clone [(https://github.com/CorentinJ/Real-Time-Voice-Cloning)](https://github.com/CorentinJ/Real-Time-Voice-Cloning)
- LightSpeech [(https://github.com/xcmyz/LightSpeech)](https://github.com/xcmyz/LightSpeech)
- FastSpeech [(https://github.com/xcmyz/FastSpeech)](https://github.com/xcmyz/FastSpeech)
- MelGAN [(https://github.com/descriptinc/melgan-neurips)](https://github.com/descriptinc/melgan-neurips)
- GAN-TTS [(https://github.com/yanggeng1995/GAN-TTS)](https://github.com/yanggeng1995/GAN-TTS)
- speech-to-text-benchmark [(https://github.com/Picovoice/speech-to-text-benchmark)](https://github.com/Picovoice/speech-to-text-benchmark)

### Audio Dataset
- datasets-CMU_Wilderness [(https://github.com/festvox/datasets-CMU_Wilderness)](https://github.com/festvox/datasets-CMU_Wilderness)
- soundnet [(https://github.com/cvondrick/soundnet)](https://github.com/cvondrick/soundnet)
- voice_datasets [(https://github.com/jim-schwoebel/voice_datasets)](https://github.com/jim-schwoebel/voice_datasets)
- css10 [(https://github.com/Kyubyong/css1)](https://github.com/Kyubyong/css1)
- css10 [(https://github.com/Kyubyong/css10)](https://github.com/Kyubyong/css10)
- SEAME-dev-set [(https://github.com/zengzp0912/SEAME-dev-set)](https://github.com/zengzp0912/SEAME-dev-set)
- MELD [(https://github.com/SenticNet/MELD)](https://github.com/SenticNet/MELD)
- open-speech-corpora [(https://github.com/JRMeyer/open-speech-corpora)](https://github.com/JRMeyer/open-speech-corpora)
- aidatatang_200zh [(https://github.com/datatang-ailab/aidatatang_200zh)](https://github.com/datatang-ailab/aidatatang_200zh)
- DALI [(https://github.com/gabolsgabs/DALI)](https://github.com/gabolsgabs/DALI)
- RadioTalk [(https://github.com/social-machines/RadioTalk)](https://github.com/social-machines/RadioTalk)
- ASR Audio data links [(https://github.com/robmsmt/ASR_Audio_Data_Links)](https://github.com/robmsmt/ASR_Audio_Data_Links)

### Speech Denoising/Enhancement
- speech-denoising-wavenet [(https://github.com/drethage/speech-denoising-wavenet)](https://github.com/drethage/speech-denoising-wavenet)
- segan [(https://github.com/santi-pdp/segan)](https://github.com/santi-pdp/segan)
- sednn [(https://github.com/yongxuUSTC/sednn)](https://github.com/yongxuUSTC/sednn)
- spec_augment [(https://github.com/zcaceres/spec_augment)](https://github.com/zcaceres/spec_augment)
- SpecAugment [(https://github.com/DemisEom/SpecAugment)](https://github.com/DemisEom/SpecAugment)
- nara_wpe [(https://github.com/fgnt/nara_wpe)](https://github.com/fgnt/nara_wpe)
- setk [(https://github.com/funcwj/setk)](https://github.com/funcwj/setk)
- single-channel-speech-enhancement [(https://github.com/zhr1201/CNN-for-single-channel-speech-enhancement)](https://github.com/zhr1201/CNN-for-single-channel-speech-enhancement)
- onssen [(https://github.com/speechLabBcCuny/onssen)](https://github.com/speechLabBcCuny/onssen)
- beamforming toolkit [(https://github.com/kkumatani/distant_speech_recognition)](https://github.com/kkumatani/distant_speech_recognition)

### Speech Emotion Recognition
- speech-emotion-recognition-exercise [(https://github.com/YJango/speech-emotion-recognition-exercise)](https://github.com/YJango/speech-emotion-recognition-exercise)
- speech-emotion-recognition [(https://github.com/xuanjihe/speech-emotion-recognition)](https://github.com/xuanjihe/speech-emotion-recognition)
- multimodal-speech-emotion [(https://github.com/david-yoon/multimodal-speech-emotion)](https://github.com/david-yoon/multimodal-speech-emotion)
- multimodal-speech-emotion-recognition [(https://github.com/Demfier/multimodal-speech-emotion-recognition)](https://github.com/Demfier/multimodal-speech-emotion-recognition)

### Speaker Recognition
- speaker-recognition-papers [(https://github.com/bjfu-ai-institute/speaker-recognition-papers)](https://github.com/bjfu-ai-institute/speaker-recognition-papers)
- DeepSpeaker-pytorch [(https://github.com/qqueing/DeepSpeaker-pytorch)](https://github.com/qqueing/DeepSpeaker-pytorch)
- 3D-convolutional-speaker-recognition [(https://github.com/astorfi/3D-convolutional-speaker-recognition)](https://github.com/astorfi/3D-convolutional-speaker-recognition)
- x-vector-kaldi-tf [(https://github.com/hsn-zeinali/x-vector-kaldi-tf)](https://github.com/hsn-zeinali/x-vector-kaldi-tf)
- ivector-xvector [(https://github.com/zeroQiaoba/ivector-xvector)](https://github.com/zeroQiaoba/ivector-xvector)


### Audio Fingerprinting

- dejavu [(https://github.com/worldveil/dejavu)](https://github.com/worldveil/dejavu)